# Custom configuration for tool use Chain of Thought enhancement
llm:
  # Provider selection: "vllm" or "api-endpoint"
  provider: "api-endpoint"

vllm:
  api_base: "http://localhost:8000/v1"
  model: "unsloth/Meta-Llama-3.3-70B-Instruct"
  max_retries: 3
  retry_delay: 1.0

# API endpoint configuration
api-endpoint:
  api_base: null # Optional base URL for API endpoint (null for default API)
  api_key: null # API key for API endpoint or compatible service (can use env var instead)
  model: "kit.gpt-oss-120b" # Default model to use
  max_retries: 3 # Number of retries for API calls
  retry_delay: 1.0 # Initial delay between retries (seconds)
  sleep_time: 0.5 # Small delay in seconds between batches to avoid rate limits

generation:
  temperature: 0.2 # Lower temperature for more consistent reasoning
  top_p: 0.95
  max_tokens: 8192 # Allow for longer outputs to accommodate CoT reasoning

# The most important part - our custom Chain of Thought prompt
prompts:
  cot_enhancement: |
    You are an expert editor of synthetic argumentation conversations from the `DebateLabKIT/argunauts-thinking` dataset.
    Your job is to improve alignment between user instructions and assistant behaviour while preserving the logical content of the assistant answers.

    You will receive one or more conversations serialized as JSON.
    Each conversation is an array of message objects with keys such as `role`, `content`, `name`, `thinking`, `tool_calls`, and `tools`.

    STRICT INVARIANTS (MUST FOLLOW):
    - Do NOT add or remove any messages.
    - Do NOT add or remove any keys in any message.
    - Do NOT change any `role`, `name`, `tool_calls`, or `tools` field.
    - For all messages with `role: "assistant"`, you MUST treat the `content` field as read-only text.
      Do not modify a single character of any `assistant.content` value.
    - You MAY rewrite the `content` field of user messages.
    - For `system` and `tool` messages, you should leave all fields unchanged.

    EXPECTED TRANSFORMATION – Thinking-focused alignment with minimal prompt edits:
    1. Prefer to keep `user` message `content` as close as possible to the original.
       - You MAY make small clarifications, fix minor phrasing, or, when necessary, add short phrases with extra hints.
       - Avoid substantially lengthening or radically rephrasing user messages; the spirit and granularity of the original instruction should remain recognizable.
       - Keep the "source text", if included in the `content` field of the user massage, fully intact.
    2. Freely edit and revise any existing and non-empty `thinking` field of assistant messages so that it:
        - Begins with 1–3 concise sentences restating, in the assistant's own words, what the user is asking for and what outcome they want.
            - Use formulations such as "The user is asking me to...", "The user faces ... and asks me to...", or "The user's goal is to...".
            - Ground this restatement in the (mostly unchanged) user prompt and do not introduce new tasks or goals unrelated to what the user did ask for.
        - Reuses the original `thinking` content as raw material: preserve all substantive reasoning steps while you reorganize and rearrange.
        - Starts from the user’s request and outlines a plausible approach to tackle it (e.g. analysing the text, extracting propositions, reconstructing arguments, running rhetorical tools, adding YAML annotations).
            - Replace overly mechanical plans with more natural, higher-level planning, as long as the reasoning still justifies why a detailed, multi-step answer is appropriate.
            - Rather than starting with overlong step lists from the original `thinking` field upfront, begin with smaller lists and add todos dynamically later on.
        - Unfolds a rich, intricate, and coherent chain of thought following the prelimary plan outlined before.
            - Use first-person present tense consistently.
            - Mix in occasional reflections, like realistic backtracking, trying alternative approaches, and short “taking stock” moments, such as: "Wait, am I really capturing the user’s focus on rhetorical style here?", "Let me reconsider whether this argument structure matches the narrative flow of the text.", "Now that I have tried plan A (purely formal reconstruction), I will instead follow the text paragraph by paragraph to get a better result."
            - You may revise or refine the initially presented plan as the `thinking` trace unfolds (e.g. add extra Argdown reconstruction steps, or postpone your tool calls), but the overall trajectory must still be traceable from the user’s request to the final answer.
            - Keep meta-cognitive commentary (e.g. backtracking notes, plan updates) purposeful and relatively brief; avoid turning the chain of thought into pure chatter.
            - Any non-linear moves should remain coherent, build on each other, and clearly move towards the existing assistant `content` and tool calls.
        - Leads naturally to the already-fixed `content` (= final answer), and tool calls (if any).


    Additional guidelines:
    - Preserve the argumentative content, Argdown structures, and logical relationships expressed in the assistant `content` exactly as given.
    - Maintain the overall style of the dataset: precise, analytic, and focused on argument mapping and applied logic.

    Output requirements:
    - Return the full conversations in the SAME JSON structure you received, with the same number of conversations and messages.
    - Only the `user.content` fields (minimally, as described above) and `assistant.thinking` fields may change.
    - Do NOT add any commentary, explanations, or markdown outside of the JSON itself.

    BEGIN WORK NOW. Rewrite the conversation(s) according to these rules:
    {conversations}
