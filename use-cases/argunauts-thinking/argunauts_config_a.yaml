# Custom configuration for tool use Chain of Thought enhancement
llm:
  # Provider selection: "vllm" or "api-endpoint"
  provider: "api-endpoint"

vllm:
  api_base: "http://localhost:8000/v1"
  model: "unsloth/Meta-Llama-3.3-70B-Instruct"
  max_retries: 3
  retry_delay: 1.0

# API endpoint configuration
api-endpoint:
  api_base: null # Optional base URL for API endpoint (null for default API)
  api_key: null # API key for API endpoint or compatible service (can use env var instead)
  model: "kit.gpt-oss-120b" # Default model to use
  max_retries: 3 # Number of retries for API calls
  retry_delay: 1.0 # Initial delay between retries (seconds)
  sleep_time: 0.5 # Small delay in seconds between batches to avoid rate limits

generation:
  temperature: 0.3 # Lower temperature for more consistent reasoning
  top_p: 0.95
  max_tokens: 8192 # Allow for longer outputs to accommodate CoT reasoning

# The most important part - our custom Chain of Thought prompt
prompts:
  cot_enhancement: |
    You are an expert editor of synthetic argumentation conversations from the `DebateLabKIT/argunauts-thinking` dataset.
    Your job is to improve alignment between user instructions and assistant behaviour while preserving the logical content of the assistant answers.

    You will receive one or more conversations serialized as JSON.
    Each conversation is an array of message objects with keys such as `role`, `content`, `name`, `thinking`, `tool_calls`, and `tools`.

    STRICT INVARIANTS (MUST FOLLOW):
    - Do NOT add or remove any messages.
    - Do NOT change any `role`, `name`, `tool_calls`, or `tools` field.
    - For all messages with `role: "assistant"`, you MUST treat the `content` field as read-only text.
      Do not modify a single character of any `assistant.content` value.
    - You MAY rewrite the `thinking` field of assistant messages.
    - For `system` and `tool` messages, you should leave all fields unchanged.

    EXPECTED TRANSFORMATION – Prompt-focused alignment with conservative thinking revision:
    1. Freely rewrite `user` message `content` so that the assistant's existing answers become a natural, explicitly requested response.
       - Make user prompts clearly guide the internal thinking by asking for multi-step argument reconstruction, Argdown formalization, inline YAML or JSON annotations, and the use of any tools present in `tools` or `tool_calls`, when that is what the assistant already does.
       - It is fine to substantially lengthen or rephrase user messages to describe the methodology, steps, and desired level of detail that match the assistant's internal reasoning and final output.
    2. Edit and integrate (do NOT replace) the existing `thinking` field of assistant messages so that it:
       - Begins with 1–3 concise sentences where the assistant restates, in its own words, what the user is asking for and what task it needs to perform.
         - Use patterns such as "The user is asking me to...", "The user faces ... and asks me to...", or "The user's goal is to...".
         - Keep this restatement short and concrete, not a generic template.
       - Reuses the original `thinking` content as raw material: preserve all substantive reasoning steps, planning structure, and references to tools, while you reorganize, clarify, and clean up the text.
       - Starts from the new, more explicit user instructions and clearly connects them to the reasoning that already existed.
       - Lays out a realistic plan or chain of thought that explains how the assistant arrives at its already-fixed `content` and tool calls.
       - References relevant steps such as understanding the text, reconstructing arguments in Argdown, formalizing premises and conclusions (for example in LaTeX), using rhetorical or fact-checking tools, and integrating YAML/JSON annotations, when appropriate.


    Additional guidelines:
    - Preserve the argumentative content, Argdown structures, and logical relationships expressed in the assistant `content` exactly as given.
    - Maintain the overall style of the dataset: precise, analytic, and focused on argument mapping and applied logic.
    - Do NOT introduce new propositions or change the meaning of existing ones in the assistant answers.
    - For `assistant.thinking`, treat the original text as something to edit and improve, not something to discard:
      - Do not delete entire reasoning chains or tool-usage descriptions that were present.
      - You may shorten repetitive meta-commentary (for example, overly long step lists) as long as all key analytical steps and tool decisions remain represented.

    Output requirements:
    - Return the full conversations in the SAME JSON structure you received, with the same number of conversations and messages.
    - Only the `user.content` fields (according to the rules above) and `assistant.thinking` fields may change.
    - Do NOT add any commentary, explanations, or markdown outside of the JSON itself.

    BEGIN WORK NOW. Rewrite the conversation(s) according to these rules:
    {conversations}
